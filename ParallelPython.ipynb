{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Parallel Programming with Python\n",
    "_Thomas Langford, Ph.D._\n",
    "\n",
    "_Yale Center for Research Computing_\n",
    "\n",
    "_Yale Wright Laboratory_\n",
    "\n",
    "_October 16, 2018_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tools and Requirements\n",
    "\n",
    "- Language: Python 3.6\n",
    "- Modules: `numpy`, `multiprocessing`, `PIL` (for imamge processing), `mpi4py`, `matplotlib`\n",
    "- Jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Comment: Python 2 versus 3\n",
    "\n",
    "- Major modules will be dropping Python2 support in 2019\n",
    "- Worth transitioning to get new features\n",
    "- This tutorial uses python 3\n",
    "- see https://wiki.python.org/moin/Python2orPython3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# How to Follow Along\n",
    "\n",
    "## Clone from GitHub\n",
    "\n",
    "Navigate to the GitHub repository: https://github.com/ycrc/parallel_python\n",
    "\n",
    "Clone or download the zip file that contains this notebook and required data.\n",
    "\n",
    "## MyBinder\n",
    "\n",
    "Launch a live AWS container with the required tools installed:\n",
    "\n",
    "https://mybinder.org/v2/gh/ycrc/parallel_python/master\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Outline and Overview\n",
    "\n",
    "- Introduction to parallel concepts\n",
    "- Classes of parallel problems\n",
    "- Python implementations of parallel processesing\n",
    "- Tools for further exploration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to parallel concepts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Serial Execution\n",
    "Typical programs operate lines sequentially:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Define an array of numbers\n",
    "foo = np.array([0, 1, 2, 3, 4, 5])\n",
    "\n",
    "# Define a function that squares numbers\n",
    "def bar(x):\n",
    "    return x * x\n",
    "\n",
    "# Loop over each element and perform an action on it\n",
    "for element in foo:\n",
    "\n",
    "        # Print the result of bar\n",
    "        print(bar(element))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The `map` function\n",
    "\n",
    "A key tool that we will utilize later is called `map`. This lets us apply a function to each element in a list or array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# (Very) inefficient way to define a map function\n",
    "def my_map(function, array):\n",
    "    # create a container for the results\n",
    "    output = []\n",
    "\n",
    "    # loop over each element\n",
    "    for element in array:\n",
    "        \n",
    "        # add the intermediate result to the container\n",
    "        output.append(function(element))\n",
    "    \n",
    "    # return the now-filled container\n",
    "    return output\n",
    "        \n",
    "my_map(bar, foo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "Python has a helpfully provided a `map` function in the standard library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(map(bar, foo))\n",
    "\n",
    "# NB: in python3 `map` is a generator, so we need to cast it to a list for this comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The built-in `map` function is much more flexible and featured than ours, so it's best to use that one instead. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallel Workers\n",
    "\n",
    "In the example we showed before, no step of the `map` call depend on the other steps. \n",
    "\n",
    "Rather than waiting for the function to loop over each value, we could create multiple instances of the function `bar`  and apply it to each value simultaneously.\n",
    "\n",
    "This is achieved with the `multiprocessing` module and a pool of workers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The `Mutiprocessing` module\n",
    "\n",
    "The `multiprocessing` module has a number of functions to help simplify parallel processing.\n",
    "\n",
    "One such tool is the `Pool` class. It allows us to set up a group of processes to excecute tasks in parallel. This is called a pool of worker processes. \n",
    "\n",
    "First we will create the pool with a specified number of workers. We will then use our `map` utility to apply a function to our array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "# Create a pool of processes\n",
    "with multiprocessing.Pool(processes=6) as pool:\n",
    "    # map the `np.square` function on our `foo` array\n",
    "    result = pool.map(np.square, foo)\n",
    "\n",
    "# output the results\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference here is that each element of this list is being handled by a different process. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To show how this is actually being handled, let's create a new function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_test(x):\n",
    "    # print the index of the job and it's process ID number\n",
    "    print(f\"x = {x}, PID = {os.getpid()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now we can map this function on the `foo` array from before. First with the built-in `map` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(map(parallel_test, foo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that each step is being handled by the same process and are excecuted in order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now we try the same process using `multiprocessing`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with multiprocessing.Pool(processes=6) as pool:\n",
    "    result = pool.map(parallel_test, foo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two things are worth noting:\n",
    "1. Each element is processed by a different PID\n",
    "2. The tasks are not executed in order!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Key Take-aways\n",
    "\n",
    "1. The `map` function is designed to apply the same function to each item in an iterator\n",
    "2. In serial processing, this works like a for-loop\n",
    "3. Parallel execution sets up multiple worker processes that act separately and simultaneously "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Classes of Parallel Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Comment: Shared vs Distributed Memory\n",
    "\n",
    "\n",
    "- **Shared Memory:** Multiple threads/processes share a single memory space with full read/write ability\n",
    "- **Distributed Memory:** Each thread/process recieves a copy of the memory space when they are first initialized. Communication is handled through message passing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Embarassingly parallel problems\n",
    "\n",
    "Many problems can be simply converted to parallel execution with the `multiprocessing` module. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example 1: Monte Carlo Simulations\n",
    "\n",
    "- Run multiple instances of the same simulation framework with different random number generator seeds\n",
    "- Define a function that takes the random seed as input, then map it on an array of random seeds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def mc_example(seed):\n",
    "    # set numpy's random seed with the input integer\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # generate a list of random numbers\n",
    "    random_list = np.random.randint(low=100, high=1000, size=10)\n",
    "    \n",
    "    return random_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_example(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "seed_array = [10,20,30,40]\n",
    "\n",
    "with multiprocessing.Pool(processes=4) as pool:\n",
    "    result = pool.map(mc_example, seed_array)\n",
    "\n",
    "for el in result:\n",
    "    print(el)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each iteration of the Monte Carlo program returns a different set of random numbers that can be used to simulate various random processes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example 2: Processing multiple input files\n",
    "\n",
    "Say we have a number of input files, like `.jpg` images, that we want to perform the same actions on, like rotate by 180 degrees and convert to a different format. \n",
    "\n",
    "We can define a function that takes a file as input and performs these actions, then map it on a list of files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# import python image library functions\n",
    "from PIL import Image\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Read image\n",
    "im = Image.open( './data/kings_cross.jpg' )\n",
    "#Display image\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "im.rotate(angle=180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function that takes a file name as input, opens the file, rotates it upside down, and then saves the output as a PDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def image_flipper(file_name):\n",
    "    # extract the base file name\n",
    "    base_name = file_name[0:-4]\n",
    "    \n",
    "    # opens the file\n",
    "    im = Image.open( file_name )\n",
    "\n",
    "    # rotates by 180deg\n",
    "    im_flipped = im.rotate(angle=180)\n",
    "    \n",
    "    # Saves a PDF output with a new file name\n",
    "    im_flipped.save(base_name + \"_flipped.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "file_list = glob.glob('./data/*jpg')\n",
    "\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with multiprocessing.Pool(processes=4) as pool:\n",
    "    pool.map(image_flipper, file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created a set of PDF files with new file names and inverted images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls ./data/*pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Parallel Processing on the Clusters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can employ these tools and techniques to execute parallel code on the large-scale computing clusters maintained by YCRC. \n",
    "\n",
    "We highly recommend utilizing a tool called Dead Simple Queue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Dead Simple Queue\n",
    "\n",
    "Similar to the `map` functionality discussed earlier is the Dead Simple Queue (`dSQ`) module available on each cluster. \n",
    "    \n",
    "    module load Tools/dSQ\n",
    "\n",
    "With this we have access to a simple way to map a function across a job array. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "    dSQ --help\n",
    "    \n",
    "    usage: dSQ --jobfile jobfile [dSQ args] [slurm args]\n",
    "\n",
    "    Dead Simple Queue v0.9\n",
    "    https://github.com/ycrc/dSQ\n",
    "    A simple utility for submitting a list of jobss as a job array using sbatch.\n",
    "    The job file should specify one independent job you want to run per line. \n",
    "    Empty lines or lines that begin with # will be ignored. Without specifying\n",
    "    any additional sbatch arguments, some defaults will be set. To generate a \n",
    "    list of the jobss that didn't run or failed, use dSQAutopsy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The basic idea is similar to `map`: create a list of parameters and pass them to a single function for processing. \n",
    "\n",
    "However, instead of doing this from within `python`, we leverage the SLURM job scheduler to divy jobs to workers. \n",
    "\n",
    "The key is the `jobfile`. Each line of this text file is a separate command-line job that we want to pass to a different worker. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## dSQ Output\n",
    "\n",
    "You can monitor the status of your jobs in Slurm by using `squeue -u <netid>`.\n",
    "\n",
    "dSQ creates a file named `job_<jobid>_status.tsv`, which will report the success or failure of each job as it finishes. Note this file will not contain information for any jobs that were canceled (e.g. by the user with scancel) before they began. This file contains details about the completed jobs in the following tab-separated columns:\n",
    "\n",
    "    Job_ID: the zero-based line number from your job file\n",
    "    Exit_Code: exit code returned from your job (non-zero number generally indicates a failed job)\n",
    "    Time_Started: time started, formatted as year-month-day hour:minute:second\n",
    "    Time_Ended: time started, formatted as year-month-day hour:minute:second\n",
    "    Time_Elapsed: in seconds\n",
    "    Job: the line from your job file\n",
    "\n",
    "Additionally, Slurm will honor the `-e,--error` and `-i,--input` arguments you provide to capture stdout and stderr. By default both standard output and standard error are directed to a file of the name `\"slurm-%j.out\"`, where the \"%j\" is replaced with the job allocation number and array index, which is conveniently also the 0-based line number from your job file. We recommend inspecting these outputs for troubleshooting individual failed jobss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# dSQ Example 1: Flipping Images\n",
    "\n",
    "We can extend the example from before to be deployed on the clusters.\n",
    "\n",
    "Our python script (`image_flipper.py`) now looks like this:\n",
    "\n",
    "```python    \n",
    "\n",
    "    from PIL import Image\n",
    "    from sys import argv\n",
    "    \n",
    "    # get the command line argument (argv[0] is the function name, argv[1] is the first argument)\n",
    "    file_name = argv[1]\n",
    "    \n",
    "    # extract the base file name\n",
    "    base_name = file_name.split('.')[0]\n",
    "    \n",
    "    # opens the file\n",
    "    im = Image.open( file_name )\n",
    "\n",
    "    # rotates by 180deg\n",
    "    im_flipped = im.rotate(angle=180)\n",
    "    \n",
    "    # Saves a PDF output with a new file name\n",
    "    im_flipped.save(base_name + \"_flipped.pdf\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Then we need to create the `jobfile.txt`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for file_name in file_list:\n",
    "    print(f'python image_flipper.py {file_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This can then be saved (`jf.txt`) passed to dSQ:\n",
    "\n",
    "    dSQ --jobfile jf.txt \n",
    "    \n",
    "Which outputs a SLURM submission script:\n",
    "\n",
    "    dSQ --jobfile jf.txt \n",
    "    #!/bin/bash\n",
    "\n",
    "    #SBATCH --job-name=jf.txt\n",
    "    #SBATCH --ntasks=1\n",
    "    #SBATCH --cpus-per-task=1\n",
    "    #SBATCH --mail-type=ALL\n",
    "    #SBATCH --mail-user=thomas.langford@yale.edu\n",
    "    #SBATCH --array=0-9\n",
    "\n",
    "    /apps/hpc.rhel7/Tools/dSQ/dSQBatch.py jf.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can either save this output as a sbatch submission script (and then run it: `sbatch run.sh`), or we can add the ``--submit`` flag to the dSQ command which will automatically submit the job array:\n",
    "\n",
    "    dSQ --jobfile jf.txt --submit\n",
    "    \n",
    "We can also add any further SLURM arguments that we need:\n",
    "\n",
    "    dSQ --jobfile jf.txt --submit --partition day -t 6:00:00 --mempercpu 10000 --cpus-per-task=1\n",
    "\n",
    "This will submit our job to the `day` partition while requesting one CPU for each task, 10GB of memory per CPU, and a wall time of 6 hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Not-so-embarassingly Parallel Problems\n",
    "\n",
    "There are also many problems that cannot be so easily split up. Many problems need to have communication between different steps and we would like a way to send messages between processes. \n",
    "\n",
    "Examples of this include simulations of galaxy formation and electic field simulations, analysis of a single large dataset, or complex `search` or `sort` algorithms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# `mpi4py`\n",
    "\n",
    "There is a standard protocol, called `MPI`, that defines how messages are passed between processes, including one-to-one and broadcast communications. \n",
    "\n",
    "The Python module for this is called `mpi4py`:\n",
    "\n",
    "[mpi4py Read The Docs](https://mpi4py.readthedocs.io/en/stable/)\n",
    "\n",
    "_Message Passing Interface implemented for Python._\n",
    "\n",
    "> Supports point-to-point (sends, receives) and collective (broadcasts, scatters, gathers) communications of any picklable Python object, as well as optimized communications of Python object exposing the single-segment buffer interface (NumPy arrays, builtin bytes/string/array objects)\n",
    "\n",
    "We will go over a few simple examples here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## First, a few definitions\n",
    "\n",
    "`COMM`: The communication \"world\" defined by MPI\n",
    "\n",
    "`RANK`: an ID number given to each internal process to define communcation\n",
    "\n",
    "`SIZE`: total number of processes allocated\n",
    "\n",
    "\n",
    "\n",
    "`BROADCAST`: One-to-many communication\n",
    "\n",
    "`SCATTER`: One-to-many data distribution\n",
    "\n",
    "`GATHER`: Many-to-one data distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Installing mpi4py\n",
    "\n",
    "By far the easiest way to install mpi4py is using Anaconda, which will also install dependences (including `MPI`).\n",
    "\n",
    "On your personal machine, run the following:\n",
    "\n",
    "    conda create --name mpi python=3.6 mpi4py numpy scipy\n",
    "    \n",
    "This creates a new `conda` environment named `mpi` with various dependences.\n",
    "\n",
    "On the clusters, you can use the `miniconda` tool to help create this environment\n",
    "\n",
    "    module load Langs/Python/miniconda\n",
    "    conda create --name mpi python=3.6 mpi4py numpy scipy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## MPI Example 1: RANK\n",
    "\n",
    "`mpi4py` doesn't run well in a notebook, so we will make a file (`mpi_simple.py`) containing the following:\n",
    "    \n",
    "```python\n",
    "from mpi4py import MPI\n",
    "\n",
    "# instantize the communication world \n",
    "comm = MPI.COMM_WORLD\n",
    "\n",
    "# get the size of the communication world \n",
    "size = comm.Get_size()\n",
    "\n",
    "# get this particular processes' `rank` ID\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "PID = os.getpid()\n",
    "\n",
    "print(f'rank: {rank} has PID: {PID}')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We then execute this code (named `mpi_simple.py`) by running the following on the command line:\n",
    "\n",
    "    mpirun -n 4 python mpi_simple.py\n",
    "\n",
    "Which outputs the following:\n",
    "\n",
    "    rank: 0 has PID: 89134 \n",
    "    rank: 1 has PID: 89135 \n",
    "    rank: 2 has PID: 89136\n",
    "    rank: 3 has PID: 89137"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "    mpirun -n 4 python mpi_simple.py\n",
    "\n",
    "The `mpirun` command is a wrapper for the MPI interface. \n",
    "\n",
    "Then we tell that to set up a `COMM_WORLD` with 4 workers. \n",
    "\n",
    "Finally we tell `mpirun` to run `python mpi_simple.py` on each of the four workers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Point to Point Communicators\n",
    "\n",
    "The most basic communication operators are \"`send`\" and \"`recv`\". These can be a bit tricky since they are \"blocking\" commands and can cause the program to hang. \n",
    "\n",
    "- `comm.send(obj, dest, tag=0)`\n",
    "- `comm.recv(source=MPI.ANY_SOURCE, tag=MPI.ANY_TAG, status=None)`\n",
    "    - `tag` can be used as a filter\n",
    "    - `dest` must be a rank in the current communicator\n",
    "    - `source` can be a rank or a wild-card (`MPI.ANY_SOURCE`)\n",
    "    - `status` used to retrieve information about recv'd message\n",
    "- NB: These are both blocking operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# MPI Example 2: `send` and `recv`\n",
    "\n",
    "We now we create a file (`mpi_comm.py`) that contains the following:\n",
    "\n",
    "```python\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "    msg = 'Hello, world'\n",
    "    comm.send(msg, dest=1)\n",
    "elif rank == 1:\n",
    "    s = comm.recv()\n",
    "    print(f\"rank {rank}: {s}\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "When we run this on the command line (`mpirun -n 4 python mpi_comm.py`) we get the following:\n",
    "\n",
    "    rank 1: Hello, world\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The `RANK=0` process sends the message, and the `RANK=1` process receives it. The other two processes are effectively bystanders in this example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# MPI Example 3: Broadcast\n",
    "\n",
    "Now we will try a slightly more complicated example that involves sending messages between processes. \n",
    "```python\n",
    "# Import MPI\n",
    "from mpi4py import MPI\n",
    "\n",
    "# Define world \n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "# Create some data in the RANK_0 worker\n",
    "if rank == 0:\n",
    "    data = {'key1' : [7, 2.72, 2+3j], 'key2' : ( 'abc', 'xyz')}\n",
    "else:\n",
    "    data = None\n",
    "\n",
    "# Broadcast the data from RANK_0 to all workers\n",
    "data = comm.bcast(data, root=0)\n",
    "\n",
    "# Append the RANK ID to the data\n",
    "data['key1'].append(rank)\n",
    "\n",
    "# Print the resulting data\n",
    "print(f\"Rank: {rank}, data: {data}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We then execute this code (named `mpi_message.py`) by running the following on the command line:\n",
    "\n",
    "    mpirun -n 4 python mpi_message.py\n",
    "\n",
    "Which outputs the following:\n",
    "\n",
    "    Rank: 0, data: {'key1': [7, 2.72, (2+3j), 0], 'key2': ('abc', 'xyz')}\n",
    "    Rank: 2, data: {'key1': [7, 2.72, (2+3j), 2], 'key2': ('abc', 'xyz')}\n",
    "    Rank: 3, data: {'key1': [7, 2.72, (2+3j), 3], 'key2': ('abc', 'xyz')}\n",
    "    Rank: 1, data: {'key1': [7, 2.72, (2+3j), 1], 'key2': ('abc', 'xyz')}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# MPI Example 4: Scatter and Gather\n",
    "\n",
    "```python\n",
    "\n",
    "# import libraries\n",
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "\n",
    "# set up MPI world\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size() # new: gives number of ranks in comm\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "# generate a large array of data on RANK_0\n",
    "numData = 100000000 # 100milion values each\n",
    "data = None\n",
    "if rank == 0:\n",
    "    data = np.random.normal(loc=10, scale=5, size=numData)\n",
    "\n",
    "# initialize empty arrays to receive the partial data\n",
    "partial = np.empty(int(numData/size), dtype='d')\n",
    "\n",
    "# send data to the other workers\n",
    "comm.Scatter(data, partial, root=0)\n",
    "\n",
    "# prepare the reduced array to recieve the processed data\n",
    "reduced = None\n",
    "if rank == 0:\n",
    "    reduced = np.empty(size, dtype='d')\n",
    "\n",
    "# Average the partial arrays, and then gather them to RANK_0\n",
    "comm.Gather(np.average(partial), reduced, root=0)\n",
    "\n",
    "if rank == 0:\n",
    "    print('Full Average:',np.average(reduced))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Again we execute this on the command line (`mpirun -n 4 python mpi/mpi_scatter.py`)\n",
    "\n",
    "Which prints: `Full Average: 10.00002060397186`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Key Take-aways\n",
    "\n",
    "1. `MPI` is a powerful tool to set up communication worlds and send data and messages between workers\n",
    "2. The `mpi4py` module provides tools for using MPI within python. \n",
    "3. This is just the begining, `mpi4py` can be used for so much more..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A relatively new tool called [`Dask`](http://docs.dask.org/en/latest/) is designed to take numpy arrays and perform tasks on different pieces of the array using parallel processing.\n",
    "\n",
    "This is like our scatter-gather example from before, but `Dask` handles all the hard work!\n",
    "\n",
    "Let's try to re-implement that example with Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client, progress\n",
    "client = Client(processes=False, threads_per_worker=4,\n",
    "                n_workers=1, memory_limit='2GB')\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "x = da.random.random((20000, 20000), chunks=(2000, 2000))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "y = x + x.T\n",
    "z = y[::2, 5000:].mean(axis=1)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Dask.Distributed on the Cluster\n",
    "\n",
    "`Dask.Distributed` is a utility to launch workers using SLURM on a cluster. \n",
    "\n",
    "_DEMO TIME!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Outlook and Further Reading\n",
    "\n",
    "Parallel processing is a vast topic with numerous posibilities of study. This tutorial is designed to give a flavor of some of the tools available in Python for small, medium, and large-scale parallel programming. \n",
    "\n",
    "There are some fantastic tutorials available for further study. I recommend the following:\n",
    "\n",
    "## Intro\n",
    "- [Python 201: A multiprocessing tutorial | The Mouse Vs. The Python](https://www.blog.pythonlibrary.org/2016/08/02/python-201-a-multiprocessing-tutorial/)\n",
    "- [Parallelism in one line - Blogomatono](http://chriskiehl.com/article/parallelism-in-one-line/)\n",
    "- [An introduction to parallel programming using Python’s multiprocessing module](https://sebastianraschka.com/Articles/2014_multiprocessing.html)\n",
    "- [Python Parallel Computing (in 60 Seconds or less) – dbader.org](https://dbader.org/blog/python-parallel-computing-in-60-seconds)\n",
    "\n",
    "## Advanced\n",
    "- [Parallel Programming with MPI For Python - Research Computing in Earth Sciences](https://rabernat.github.io/research_computing/parallel-programming-with-mpi-for-python.html)\n",
    "- [Parallel Computing in Python using mpi4py by Stephen Weston](https://github.com/ycrc/parallel_python/blob/master/mpi/mpi4py.pdf)\n",
    "\n",
    "## GPU Parallelism\n",
    "- [CuPy, a Numpy-like API for GPU processing](https://docs-cupy.chainer.org/en/stable/)\n",
    "- [PyCUDA, CUDA API for python](https://documen.tician.de/pycuda/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thanks!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
